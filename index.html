<!doctype html>
<html class="gr__sunghoonim_github_io">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>sunghoonim.github.io by Sunghoon</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body data-gr-c-s-loaded="true">
    <div class="wrapper">
        <table>
            <tbody>
                <tr> 
                    <td width = "240">
                        <img src="/assets/img/sh.jpg" width = "300">
                    </td>
                    <td>
                        <h1> Sunghoon Im </h1>

                        <em>Assistant Professor</em><br>
                        <em><a href="https://cvlab.dgist.ac.kr">Computer Vision Lab.</a></em><br>
                        <em><a href="http://ice.dgist.ac.kr">Information and Communication Engineering</a></em>, <a href="https://www.dgist.ac.kr">DGIST</a><br>
                        Email: sunghoonim [at] dgist.ac.kr<br>
                        <a href="https://scholar.google.co.kr/citations?hl=ko&imq=Sunghoon+Im&user=37fSLtAAAAAJ">Google Scholar</a> |
                        <a href="https://dblp.org/pid/174/1228.html">dblp</a> |
                        <a href="https://github.com/sunghoonim">Github</a> |
                        <a href="https://www.linkedin.com/in/sunghoon-im-868916b3/">Linkedin</a> 
                        <a href="/assets/cv.pdf">.</a>
                    </td>
                </tr>
            </tbody>
        </table>
        <table>
            <p> <h4>I am an assistant professor at the department of Information and Communication Engineering at DGIST, South Korea, working as a faculty member of <a href="http://cvlab.dgist.ac.kr">DGIST Computer Vision Lab</a>. My research lies in the areas of computer vision and machine learning, especially in the problem of 3D reconstruction, Scene understanding, Image/Video synthesis and Vision for new-type sensors. </h4> </p>
            <p> <h4>I received my M.S and Ph.D degrees in Electrical Engineering from KAIST, Korea in 2016 and 2019 respectively. During my graduate study, I worked at the Robotics and Computer Vision Lab with Prof. <a href="http://rcv.kaist.ac.kr">In So Kweon</a> as my advisor. I was research intern at Microsoft Research, Beijing in 2018, and visiting scholar at Carnegie Mellon University in 2019. I received my Bachelor degree in Electronic Engineering from Sogang university (Summa cum laude) in 2014. 
        </table>

            <ul>
                <li><h2>International Journals</h2></li>
        <table>
            <tbody>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/Blank.png" width = "210">
                    </td>
                    <td>
                        <b>CMSNet: Deep Color and Monochrome Stereo</b><br>
                        Hae-Gon Jeon, <b>Sunghoon Im</b>, Jaesung Choe, Minjun Kang, Joon-Young Lee, Martial Hebert
                        International Journal of Computer Vision (<b>IJCV</b>), Accepted<br>
                        [PDF]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/PAMI_DISC.png" width = "210">
                    </td>
                    <td>
                        <b>A Large-scale Virtual Dataset and Egocentric Localization for Disaster Responses</b><br>
                        Hae-Gon Jeon, <b>Sunghoon Im</b>, Byeong-Uk Lee, François Rameau, Dong-Geol Choi, Jean Oh, In So Kweon, and Martial Hebert <br>
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Accepted<br>
                        [<a href="https://ieeexplore.ieee.org/abstract/document/9476992">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/TPAMI_DDUC.png" width = "210">
                    </td>
                    <td>
                        <b>Deep Depth from Uncalibrated Small Motion Clip</b><br>
                        <b>Sunghoon Im</b>, Hyowon Ha, Hae-Gon Jeon, Stephen Lin, In So Kweon <br>
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Apr 2021<br>
                        <em>- Selected as Outstanding Research Achievement of GIST</em><br>
                        [<a href="http://ieeexplore.ieee.org/abstract/document/8865619">Paper</a>]
                    </td>
                </tr>
                    <td width = "210">
                        <img src="/assets/img/TIP_RDF.png" width = "210">
                    </td>
                    <td>
                        <b>Ring Difference Filter for Fast and Noise Robust Depth from Focus</b><br>
                        Hae-Gon Jeon, Jaeheung Surh, <b>Sunghoon Im</b>, In So Kweon <br>
                        IEEE Transactions Image Processing (<b>TIP</b>), Dec 2020<br>
                        [<a href="http://ieeexplore.ieee.org/document/8818667">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/TIP_DfAEB.png" width = "210">
                    </td>
                    <td>
                        <b>Robust Depth Estimation using Auto-Exposure Bracketing</b><br>
                        <b>Sunghoon Im</b>, Hae-Gon Jeon, In So Kweon <br>
                        IEEE Transactions Image Processing (<b>TIP</b>), May 2019<br>
                        [<a href="http://ieeexplore.ieee.org/document/8576538">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/PAMI18_Accurate.png" width = "210">
                    </td>
                    <td>
                        <b>Accurate 3D Reconstruction from Small Motion Clip for Rolling Shutter Cameras</b><br>
                        <b>Sunghoon Im</b>, Hyowon Ha, Gyeongmin Choe,  Hae-Gon Jeon, Kyungdon Joo, In So Kweon <br>
                        IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), Apr 2019<br>
                        [<a href="http://ieeexplore.ieee.org/abstract/document/8325527/">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/RAL18_RANUS.jpg" width = "210">
                    </td>
                    <td>
                        <b>RANUS: RGB and NIR Urban Scene Dataset for Deep Scene Parsing</b><br>
                        Gyeongmin Choe, Seong-heum Kim, <b>Sunghoon Im</b>, Joon-Young Lee, Srinivasa Narasimhan,  In So Kweon <br>
                        IEEE Robotics and Automation Letters (<b>RAL</b>), July 2018<br>
                        [<a href="http://ieeexplore.ieee.org/document/8279453/">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/SPL17_Propagation.png" width = "210">
                    </td>
                    <td>
                        <b>Geometry Guided 3D Propagation for Depth from Small Motion</b><br>
                        Seunghak Shin, <b>Sunghoon Im</b>, Inwook Shim, Hae-Gon Jeon, In So Kweon <br>
                        IEEE Signal Processing Letters (<b>SPL</b>), Dec 2017<br>
                        [<a href="http://ieeexplore.ieee.org/document/8063412/">Paper</a>]
                    </td>
                </tr>
            </tbody> 
        </table>
                <li><h2>International Conferences</h2></li>
        <table>
            <tbody>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/BMVC21_Zebra.png" width = "210">
                    </td>
                    <td>
                        <b> ZeBRA: Precisely Destroying Neural Networks with Zero-Data Based Repeated Bit Flip Attack</b><br>
                        Dahoon Park, Kon-Woo Kwon, <b>Sunghoon Im</b>, Jaeha Kung <br>
                        British Machine Vision Conference (<b>BMVC</b>), 2021 <br>
                        [Paper]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICCV21_Volume.png" width = "210">
                    </td>
                    <td>
                        <b> VolumeFusion: Deep Depth Fusion for 3D Scene Reconstruction</b><br>
                        Jaesung Choe, <b>Sunghoon Im</b>, François Rameau, Minjun Kang, In So Kweon <br>
                        IEEE International Conference on Computer Vision (<b>ICCV</b>), 2021 <br>
                        [<a href="https://arxiv.org/abs/2108.08623">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPRW21_Profeat.png" width = "210">
                    </td>
                    <td>
                        <b> ProFeat: Unsupervised Image Clustering via Progressive Feature Refinement</b><br>
                        Jeonghoon Kim, <b>Sunghoon Im</b>, Sunghyun Cho <br>
                        CVPR workshop on Learning From Limited or Imperfect Data (<b>CVPRw</b>), 2021 <br>
                        [<a href="/assets/paper/CVPRW21_Profeat.pdf">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPR21_DRANet.png" width = "210">
                    </td>
                    <td>
                        <b> DRANet: Disentangling Representation and Adaptation Networks for Unsupervised Cross-Domain Adaptation</b><br>
                        Seunghun Lee, Sunghyun Cho, <b>Sunghoon Im</b> <br>
                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021<br>
                        [<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_DRANet_Disentangling_Representation_and_Adaptation_Networks_for_Unsupervised_Cross-Domain_Adaptation_CVPR_2021_paper.html">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/AAAI21_Learning.gif" width = "210">
                    </td>
                    <td>
                        <b> Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency</b><br>
                        Seokju Lee, <b>Sunghoon Im</b>, Stephen Lin, In So Kweon <br>
                        The Thirty-Fifth AAAI Conference on Artiﬁcial Intelligence (<b>AAAI</b>), 2021<br>
                        <em>- Qualcomm Innovation Fellowship Korea 2020</em><br> 
                        <em>- Silver Prize, 16th Samsung Electro-Mechanics Best Paper Awards</em><br>
                        [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/16281">Paper</a>][<a href="https://sites.google.com/site/seokjucv/home/instadm">Project page</a>][<a href="https://github.com/SeokjuLee/Insta-DM">Source code</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/NIPSw20_Instance.png" width = "210">
                    </td>
                    <td>
                        <b> Instance-wise Depth and Motion Learning from Monocular Videos</b><br>
                        Seokju Lee, <b>Sunghoon Im</b>, Stephen Lin, In So Kweon <br>
                        NeurIPS workshop on Machine Learning for Autonomous Driving (<b>NeurIPSw</b>), 2020<br>
                        NeurIPS workshop on Differentiable computer vision, graphics, and physics in machine learning (<b>NeurIPSw</b>), 2020<br>
                        <em>Honorable Mention, 12th Electronic Times ICT Paper Contest</em><br>
                        [<a href="https://arxiv.org/abs/1912.09351">Paper</a>] [<a href="https://sites.google.com/site/seokjucv/home/instadm">Project page</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICRA20_Shape.png" width = "210">
                    </td>
                    <td>
                        <b> Learning Shape-based Representation for Visual Localization in Extremely Changing Conditions</b><br>
                        Hae-Gon Jeon, <b>Sunghoon Im</b>, Jean Oh, Martial Hebert <br>
                        IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2020<br>
                        [<a href="https://www.cs.cmu.edu/afs/cs/Web/People/jeanoh/papers/JIOH-vislocal-ICRA2020.pdf">Paper</a>] [<a href="https://sites.google.com/site/hgjeoncv/disc-project-page">Project page</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/IROS19_DISC.png" width = "210">
                    </td>
                    <td>
                        <b>DISC: A Large-scale Virtual Dataset for Simulating Disaster Scenarios</b><br>
                        Hae-Gon Jeon, <b>Sunghoon Im</b>, Byeong-Uk Lee, Dong-Geol Choi, Martial Hebert, In So Kweon <br>
                        IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2019<br>
                        [<a href="https://www.ri.cmu.edu/wp-content/uploads/2019/06/IROS19_DISC_final_v1.pdf">Paper</a>] [<a href="https://sites.google.com/site/hgjeoncv/disc-project-page">Project page</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/IROS19_Sceneflow.png" width = "210">
                    </td>
                    <td>
                        <b>Learning Residual Flow as Dynamic Motion from Stereo Video</b><br>
                        Seokju Lee, <b>Sunghoon Im</b>, Stephen Lin, In So Kweon <br>
                        IEEE/RSJ International Conference on Intelligence Robots and Systems (<b>IROS</b>), 2019<br>
                        [<a href="https://arxiv.org/abs/1909.06999">Paper</a>] [<a href="https://sites.google.com/site/seokjucv/resflownet">Project page</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICLR19_DPSNET.png" width = "210">
                    </td>
                    <td>
                        <b>DPSNet: End-to-end Deep Plane Sweep Stereo</b><br>
                        <b>Sunghoon Im</b>, Hae-Gon Jeon, Stephen Lin, In So Kweon <br>
                        International Conference on Learning Representations (<b>ICLR</b>), 2019<br>
                        [<a href="https://openreview.net/pdf?id=ryeYHi0ctQ">Paper</a>] [<a href="h[ttps://github.com/sunghoonim/DPSNet">Source code</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICRA19_DeepCompletion.png" width = "210">
                    </td>
                    <td>
                        <b>Depth Completion with Deep Geometry and Context Guidance</b><br>
                        Byeong-Uk Lee, Hae-Gon Jeon, <b>Sunghoon Im</b>, In So Kweon <br>
                        IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2019<br>
                        [<a href="https://www.ri.cmu.edu/wp-content/uploads/2019/02/ICRA2019_final.pdf">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPR18_DfAB.png" width = "210">
                    </td>
                    <td>
                        <b>Robust Depth Estimation from Auto Bracketed Images</b><br>
                        <b>Sunghoon Im</b>, Hae-Gon Jeon, In So Kweon <br>
                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018<br>
                        <em>- Best Poster Award, Samsung AI Forum 2018</em><br>
                        [<a href="https://arxiv.org/abs/1803.07702">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPR17_RDF.png" width = "210">
                    </td>
                    <td>
                        <b>Noise Robust Depth from Focus using a Ring Difference Filter</b><br>
                        Jaeheung Surh, Hae-Gon Jeon, Yunwon Park, <b>Sunghoon Im</b>, Hyowon Ha, In So Kweon <br>
                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2017 (<b>Spotlight</b>)<br>
                        [<a href="/assets/paper/CVPR17_RDF.pdf">Paper</a>] [<a href="https://jaeheungs.github.io/pubs/2017-07-01-ring-difference-filter.html">Project page</a>]
                    </td>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ECCV16_Allaround.png" width = "210">
                    </td>
                    <td>
                        <b>All-around Depth from Small Motion with A Spherical Panoramic Camera</b><br>
                        <b>Sunghoon Im</b>, Hyowon Ha, Francois Rameau, Hae-Gon Jeon, Gyeongmin Choe, In So Kweon <br>
                        European Conference on Computer Vision (<b>ECCV</b>), 2016<br>
                        <em>- Best Poster Presentation Award, 29th IPIU 2017</em><br>
                        [<a href="/assets/paper/ECCV16_Allaround.pdf">Paper</a>] [<a href="https://github.com/sunghoonim/ADfSM">Source code</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPR16_High.png" width = "210">
                    </td>
                    <td>
                        <b>High-quality Depth from Uncalibrated Small Motion Clip</b><br>
                        Hyowon Ha, <b>Sunghoon Im</b>, Jaesik Park, Hae-Gon Jeon, In So Kweon <br>
                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016 (<b>Oral</b>)<br>
                        <em>- Qualcomm Innovation Award, Qualcomm-KAIST Innovation Awards 2016</em><br>
                        [<a href="/assets/paper/CVPR16_High.pdf">Paper</a>] [<a href="https://github.com/sunghoonim/DfUSMC">Source code</a>]<br>
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/CVPR16_RGBW.png" width = "210">
                    </td>
                    <td>
                        <b>Stereo Matching with Color and Monochrome Cameras in Low-light Conditions</b><br>
                        Hae-Gon Jeon, Joon-Young Lee, <b>Sunghoon Im</b>, Hyowon Ha, In So Kweon <br>
                        IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2016<br>
                        <em>- Silver Prize, 22nd HumanTech Paper Award, Samsung Electronics Co., Ltd.</em><br>
                        <em>- Best Poster Presentation Award, 29th IPIU 2017</em><br>
                        [<a href="/assets/paper/CVPR16_RGBW.pdf">Paper</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICCV15_High.jpg" width = "210">
                    </td>
                    <td>
                        <b>High Quality Structure from Small Motion for Rolling Shutter Cameras</b><br>
                        <b>Sunghoon Im</b>, Hyowon Ha, Gyeongmin Choe, Hae-Gon Jeon, Kyungdon Joo, In So Kweon <br>
                        IEEE International Conference on Computer Vision (<b>ICCV</b>), 2015<br>
                        <em>- Best Poster Award, IWRCV 2015</em><br>
                        [<a href="/assets/paper/ICCV15_High.pdf">Paper</a>] [<a href="https://github.com/sunghoonim/SfSM">Source code</a>]
                    </td>
                </tr>
                <tr> 
                    <td width = "210">
                        <img src="/assets/img/ICIP15_Depth.jpg" width = "210">
                    </td>
                    <td>
                        <b>Depth from Accidental Motion using Geometry Prior</b><br>
                        <b>Sunghoon Im</b>, Gyeongmin Choe, Hae-Gon Jeon, In So Kweon <br>
                        IEEE International Conference on Image Processing (<b>ICIP</b>), 2015 (<b>Top 10%</b>)<br>
                        [<a href="/assets/paper/ICIP15_Depth.pdf">Paper</a>]
                    </td>
                </tr>
                </tr>
            </tbody> 
        </table>
                <li><h2>Other Publications</h2></li>
        <ul>
            <li> <b>Depth Estimation from Light Field Cameras</b><br>
                 <b>Sunghoon Im</b>, Hae-Gon Jeon, Hyowon Ha and In So Kweon<br>
                 In Proc. of the 12th International Conference on Ubiquitous Robots and Ambient Intelligence (<b>URAI</b>), Oct 2015.
            </li>
            <li> <b>Relative Attributes with Deep Convolutional Neural Network</b><br>
                 Dong-jin Kim, Donggeun Yoo, <b>Sunghoon Im</b>, Namil Kim, T.Sirinukul wattana and In So Kweon<br>
                 In Proc. of the 12th International Conference on Ubiquitous Robots and Ambient Intelligence (<b>URAI</b>), Oct 2015.
            </li>
        </ul>
                <li><h2>Patents</h2></li>
        <ul> 
            <li> <b>METHOD AND APPARATUS FOR ESTIMATING DEPTH USING RING DIFFERENCE FILTER</b><br>
                 Publication date: Sep 28, 2018. (10-2017-0091717) </li>
            <li> <b>DEPTH MAP ACQUISITION DEVICE AND DEPTH MAP ACQUISITION METHOD</b><br>
                 Publication date: Apr 19, 2018. (10-2016-0103546) </li>
            <li> <b>METHOD AND APPARATUS FOR ACQUIRING DEPTH MAP FROM ALL-AROUND CAMERA</b><br>
                 Publication date: Apr 17, 2018. (10-2016-0167525) </li>
            <li> <b>DEPTH INFORMATION ACQUIRING DEVICE AND METHOD THEREOF</b><br>
                 Publication date: Aug 11, 2017. (10-2016-0076766) </li>
            <li> <b>APPARATUS AND METHOD FOR DEPTH MAP GENERATION</b><br>
                 Publication date: Jun. 02, 2016. (10-2016-0015703) </li>
        </ul>
                <li><h2>Academic Activities</h2></li>
        <ul>
          <li> Teaching
              <ul>
              <li> Introduction to Deep Learning, 2020, 2021.</li>
              <li> Deep Learning, 2020.</li>
              <li> Computer Vision, 2019.</li>
              </ul>
          </li>
          <li> Academic Services
              <ul>
              <li> Editor - The Information and Communications Technology Express (ICT Express).</li>
              <li> Local chair - International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)</li>
              </ul>
          </li>
          <li>Reviewer (International Journal)
              <ul>
              <li> International Journal of Computer Vision (IJCV).</li>
              <li> Computer Vision and Image Understanding (CVIU).</li> 
              <li> Pattern Recognition (PR).</li>
              <li> Neurocomputing.</li>
              <li> IEEE Robotics and Automation Letters (RAL) </li>
              <li> IEEE Access.</li>
              <li> International Journal of Control, Automation and Systems (IJCAS).</li>
              <li> IEIE Transactions on Smart Processing and Computing (IEIE SPC).</li>
              <li> Journal of Institute of Control, Robotics and System (ICROS).</li>
              </ul>
          </li>
          <li>Reviewer (International Conference)
              <ul>
              <li> IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2019-2022.</li>
              <li> IEEE International Conference on Computer Vision (ICCV) 2019.</li>
              <li> European Conference on Computer Vision (ECCV) 2020.</li>
              <li> Conference on Neural Information Processing Systems (NeurIPS) 2020-2021.</li>
              <li> International Conference on Machine Learning (ICML) 2020-2021.</li>
              <li> International Conference on Learning Representations (ICLR) 2021-2022.</li>
              <li> Association for the Advancement of Artificial Intelligence (AAAI) 2020-2022.</li>
              <li> IEEE International Conference on Robotics and Automation (ICRA), 2021.</li>
              <li> IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2017.</li>
              <li> Asian Conference on Computer Vision (ACCV) 2020.</li>
              <li> IEEE Winter Conference on Applications of Computer Vision (WACV), 2020.</li>
              <li> International Conference on 3D Vision (3DV) 2020.</li>
              <li> International Conference on Control, Automation and Systems (ICCAS), 2020.</li>
              </ul>
          </li>
          <li>Tutorial
              <ul>
                  <li> Multiple View Geometry, KETI Sangam, Aug-Oct 2020.</li>
              </ul>
          </li>
          <li>Talks
              <ul>
                  <li> 31st Signal Processing Joint Conference, IEIE, Online, Sep 2021.</li>
                  <li> 2nd Korea Artificial Intelligence Conference, Jeju, Sep 2021.</li>
                  <li> Kyungpook National University, Daegu, Sep 2021.</li>
                  <li> KCCV (Korean Conference on Computer Vision), Seoul, Sep 2021.</li>
                  <li> The Korean Institute of Broadcast and Media Engineers, Gyeongju, Apr 2021.</li>
                  <li> ETRI (Electronics and Telecommunications Research Institute) Daejeon, Oct 2020.</li>
                  <li> ETRI (Electronics and Telecommunications Research Institute) Daegu, Oct 2020.</li>
                  <li> GIST, Jun 2020.</li>
                  <li> KETI (Korea Electronics Technology Institute) Sangam, Jan 2020.</li>
                  <li> POSTECH, Dec 2019.</li>
                  <li> KETI (Korea Electronics Technology Institute) Pangyo, Nov 2019.</li>
                  <li> DGIF (Daegu Technopolis Grand Innovation Festival), Oct 2019.</li>
                  <li> ETRI (Electronics and Telecommunications Research Institute) Daejeon, Sep 2019.</li>
                  <li> Sogang University, Sep 2019.</li>
                  <li> Lunit, Aug 2019.</li>
                  <li> SAIT (Samsung Advanced Institute of Technology), Apr 2019.</li>
                  <li> Koh Young Technology, Jan 2019.</li>
                </ul>
          </li>
        </ul>
                <li><h2>Awards & Honors</h2></li>
        <ul>
            <li>Awards
                <ul>
          <li>Best Academic Award, DGIST, Sep 2021.</li>
          <li>Excellent Student Award, 2018 Rearch Performance Evaluation, KAIST EE, Apr 2019.</li>
          <li>Best Poster Award, 2018 Samsung AI Forum, Samsung Research, Sep 2018.</li>
          <li>Excellent Intern Award, Microsoft Research Asia (MSRA), Aug 2018.</li>
          <li>Honor Student Award, 2017 Reserch Performance Evaluation, KAIST EE, Apr 2018.</li>
          <li>Kim Choong-Ki Award, 2016 Reserch Performance Evaluation, KAIST EE, Apr 2017.</li>
          <li>Best Poster presentation Award, 29th Workshop on Image Processing and Image Understanding (IPIU), Feb 2017.</li>
          <li>Qualcomm Innovation Award 2016, Qualcomm Korea Corp. and KAIST, Apr 2016.
          <li>Silver prize, 22nd HumanTech Paper Award, Samsung Electronics Co., Ltd., Feb 2016.
          <li>Official Best 10% Paper Selection, ICIP 2015 Organizing Committe, Sep 2015.
          <li>Summa Cum Laude, Sogang University, Feb 2014.</li>
          <li>Silver Prize, Design project competition, Sogang University, Nov 2013.</li>
          <li>Prize for the top first percential GPA, Sogang University, Sep 2011, Mar 2012, and Sep 2012. </li>
          </ul>
          <li> Honors
              <ul>
          <li>NeurIPS 2020 Top 10% of high-scoring reviewer, Oct 2020.</li>
          <li>CVPR 2019 Doctoral Consortium, Jun 2019.</li>
          <li>ICLR 2019 Travel Award, May 2019.</li>
          <li>Microsoft Research Asia (MSRA) Fellowship 2018 Winner, Oct 2018.</li>
          <li>International Computer Vision Summer School (ICVSS 2016), Jul 2016.
          <li>Global Ph.D Fellowship, National Research Foundation of Korea (about $20,000 + Full scholarship per year for 2+1 years).</li>
        </ul>
                </ul>
    </div>
    <script src="javascripts/scale.fix.js"></script>
  </body>
</html>
